import streamlit as st
import os
import tempfile
from langchain.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain.output_parsers import PydanticOutputParser
from langchain_core.pydantic_v1 import BaseModel, Field
from typing import List
from langchain.chains import ConversationalRetrievalChain
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="AIå·¥å…·é›†åˆ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å°çº¢ä¹¦æ¨¡å‹å®šä¹‰
class XiaoHongShu(BaseModel):
    titles: List[str] = Field(description='å°çº¢ä¹¦çš„5ä¸ªæ ‡é¢˜', min_items=5, max_items=10)
    content: str = Field(description='å°çº¢ä¹¦çš„æ­£æ–‡å†…å®¹')

# åˆå§‹åŒ–session state
if 'selected_page' not in st.session_state:
    st.session_state.selected_page = "é¦–é¡µ"

# å…¨å±€ä¾§æ APIå¯†é’¥è¾“å…¥
with st.sidebar:
    st.title("ğŸ¤– AIå·¥å…·é›†åˆ")
    st.markdown("---")
    
    # APIå¯†é’¥è¾“å…¥
    openai_api_key = st.text_input('è¯·è¾“å…¥OpenAI APIå¯†é’¥', type='password', key='global_api_key')
    if openai_api_key:
        st.success("âœ… APIå¯†é’¥å·²è®¾ç½®")
    else:
        st.warning("âš ï¸ è¯·è¾“å…¥APIå¯†é’¥ä»¥ä½¿ç”¨AIåŠŸèƒ½")
    
    st.markdown("[è·å–OpenAI APIå¯†é’¥](https://openai-hk.com/v3/ai/key)")
    st.markdown("---")
    
    # ä¾§æ æŒ‰é’®
    if st.button("ğŸ  é¦–é¡µ", use_container_width=True):
        st.session_state.selected_page = "é¦–é¡µ"
    
    if st.button("ğŸ¬ ä¸€é”®ç”Ÿæˆè§†é¢‘è„šæœ¬", use_container_width=True):
        st.session_state.selected_page = "è§†é¢‘è„šæœ¬"
    
    if st.button("ğŸ“ ç”Ÿæˆå°çº¢ä¹¦çˆ†æ¬¾æ–‡æ¡ˆ", use_container_width=True):
        st.session_state.selected_page = "å°çº¢ä¹¦æ–‡æ¡ˆ"
    
    if st.button("ğŸ’¬ å…‹éš†ChatGPT", use_container_width=True):
        st.session_state.selected_page = "ChatGPTå…‹éš†"
    
    if st.button("ğŸ“„ PDFæ–‡æ¡£é—®ç­”å·¥å…·", use_container_width=True):
        st.session_state.selected_page = "PDFé—®ç­”"
    
    st.markdown("---")
    st.markdown("### ğŸ“ è”ç³»æˆ‘ä»¬")
    st.markdown("å¦‚æœ‰é—®é¢˜ï¼Œè¯·è”ç³»å¼€å‘å›¢é˜Ÿ")

# å·¥å…·å‡½æ•°
def generate_script(subject, video_length, creativity, api_key):
    """ç”Ÿæˆè§†é¢‘è„šæœ¬"""
    title_template = ChatPromptTemplate.from_messages([
        ('human', 'è¯·ä¸º{subject}è¿™ä¸ªä¸»é¢˜çš„è§†é¢‘æƒ³ä¸€ä¸ªå¸å¼•äººçš„æ ‡é¢˜')
    ])

    script_template = ChatPromptTemplate.from_messages([
        ('human', """
            ä½ æ˜¯ä¸€ä½çŸ­è§†é¢‘é¢‘é“çš„åšä¸»ã€‚æ ¹æ®ä»¥ä¸‹æ ‡é¢˜å’Œç›¸å…³ä¿¡æ¯ï¼Œä¸ºçŸ­è§†é¢‘é¢‘é“å†™ä¸€ä¸ªè§†é¢‘è„šæœ¬ã€‚
            è§†é¢‘æ ‡é¢˜ï¼š{title}ï¼Œè§†é¢‘æ—¶é•¿ï¼š{duration}åˆ†é’Ÿï¼Œç”Ÿæˆçš„è„šæœ¬çš„é•¿åº¦å°½é‡éµå¾ªè§†é¢‘æ—¶é•¿çš„è¦æ±‚ã€‚
            è¦æ±‚å¼€å¤´æŠ“ä½çœ¼çƒï¼Œä¸­é—´æä¾›å¹²è´§å†…å®¹ï¼Œç»“å°¾æœ‰æƒŠå–œï¼Œè„šæœ¬æ ¼å¼ä¹Ÿè¯·æŒ‰ç…§ã€å¼€å¤´ã€ä¸­é—´ï¼Œç»“å°¾ã€‘åˆ†éš”ã€‚
            æ•´ä½“å†…å®¹çš„è¡¨è¾¾æ–¹å¼è¦å°½é‡è½»æ¾æœ‰è¶£ï¼Œå¸å¼•å¹´è½»äººã€‚
        """)
    ])

    model = ChatOpenAI(
        base_url='https://api.openai-hk.com/v1/',
        openai_api_key=api_key,
        temperature=creativity
    )
    
    title_chain = title_template | model
    script_chain = script_template | model

    title = title_chain.invoke({'subject': subject}).content
    script = script_chain.invoke({'title': title, 'duration': video_length}).content

    return title, script

def generate_xiaohongshu(theme, api_key):
    """ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆ"""
    system_template_text = '''
    ä½ æ˜¯å°çº¢ä¹¦çˆ†æ¬¾å†™ä½œä¸“å®¶ï¼Œè¯·ä½ éµå¾ªä»¥ä¸‹æ­¥éª¤è¿›è¡Œåˆ›ä½œï¼š
    é¦–å…ˆäº§å‡º5ä¸ªæ ‡é¢˜ï¼ˆåŒ…å«é€‚å½“çš„emojiè¡¨æƒ…ï¼‰ï¼Œç„¶åäº§å‡º1æ®µæ­£æ–‡ï¼ˆæ¯ä¸€ä¸ªæ®µè½åŒ…å«é€‚å½“çš„emojiè¡¨æƒ…ï¼Œæ–‡æœ«æœ‰é€‚å½“çš„tagæ ‡ç­¾ï¼‰ã€‚
    æ ‡é¢˜å­—æ•°åœ¨20ä¸ªå­—ä»¥å†…ï¼Œæ­£æ–‡å­—æ•°åœ¨800å­—ä»¥å†…ï¼Œå¹¶ä¸”æŒ‰ä»¥ä¸‹æŠ€å·§è¿›è¡Œåˆ›ä½œã€‚
    
    ä¸€ã€æ ‡é¢˜åˆ›ä½œæŠ€å·§ï¼š 
    1. é‡‡ç”¨äºŒæç®¡æ ‡é¢˜æ³•è¿›è¡Œåˆ›ä½œ 
    2. ä½¿ç”¨å…·æœ‰å¸å¼•åŠ›çš„æ ‡é¢˜ 
    3. ä½¿ç”¨çˆ†æ¬¾å…³é”®è¯ï¼šå¥½ç”¨åˆ°å“­ã€å¤§æ•°æ®ã€æ•™ç§‘ä¹¦èˆ¬ã€å°ç™½å¿…çœ‹ã€å®è—ã€ç»ç»å­ã€ç¥å™¨ã€éƒ½ç»™æˆ‘å†²ã€åˆ’é‡ç‚¹ã€ç¬‘ä¸æ´»äº†ã€YYDSã€ç§˜æ–¹ã€æˆ‘ä¸å…è®¸ã€å‹ç®±åº•ã€å»ºè®®æ”¶è—ã€åœæ­¢æ‘†çƒ‚ã€ä¸Šå¤©åœ¨æé†’ä½ ã€æŒ‘æˆ˜å…¨ç½‘ã€æ‰‹æŠŠæ‰‹ã€æ­ç§˜ã€æ™®é€šå¥³ç”Ÿã€æ²‰æµ¸å¼ã€æœ‰æ‰‹å°±èƒ½åšã€å¹çˆ†ã€å¥½ç”¨å“­äº†ã€æé’±å¿…çœ‹ã€ç‹ ç‹ æé’±ã€æ‰“å·¥äººã€åè¡€æ•´ç†ã€å®¶äººä»¬ã€éšè—ã€é«˜çº§æ„Ÿã€æ²»æ„ˆã€ç ´é˜²äº†ã€ä¸‡ä¸‡æ²¡æƒ³åˆ°ã€çˆ†æ¬¾ã€æ°¸è¿œå¯ä»¥ç›¸ä¿¡ã€è¢«å¤¸çˆ†ã€æ‰‹æ®‹å…šå¿…å¤‡ã€æ­£ç¡®å§¿åŠ¿
    4. æ§åˆ¶å­—æ•°åœ¨20å­—ä»¥å†…ï¼Œä»¥å£è¯­åŒ–çš„è¡¨è¾¾æ–¹å¼
    
    äºŒã€æ­£æ–‡åˆ›ä½œæŠ€å·§
    1. å†™ä½œé£æ ¼ï¼šä»ä¸¥è‚ƒã€å¹½é»˜ã€æ„‰å¿«ã€æ¿€åŠ¨ã€æ²‰æ€ã€æ¸©é¦¨ã€å´‡æ•¬ã€è½»æ¾ã€çƒ­æƒ…ã€å®‰æ…°ã€å–œæ‚¦ã€æ¬¢ä¹ã€å¹³å’Œã€è‚¯å®šã€è´¨ç–‘ã€é¼“åŠ±ã€å»ºè®®ã€çœŸè¯šã€äº²åˆ‡ä¸­é€‰æ‹©
    2. å†™ä½œå¼€ç¯‡æ–¹æ³•ï¼šå¼•ç”¨åäººåè¨€ã€æå‡ºç–‘é—®ã€è¨€ç®€æ„èµ…ã€ä½¿ç”¨æ•°æ®ã€åˆ—ä¸¾äº‹ä¾‹ã€æè¿°åœºæ™¯ã€ç”¨å¯¹æ¯”
    
    {parser_instructions}
    '''

    prompt = ChatPromptTemplate.from_messages([
        ('system', system_template_text),
        ('user', '{theme}')
    ])

    model = ChatOpenAI(
        base_url="https://api.openai-hk.com/v1",
        openai_api_key=api_key,
        model='gpt-3.5-turbo'
    )
    
    output_parser = PydanticOutputParser(pydantic_object=XiaoHongShu)
    chain = prompt | model | output_parser
    
    result = chain.invoke({
        'parser_instructions': output_parser.get_format_instructions(), 
        'theme': theme
    })
    
    return result

def get_chat_response(prompt, memory, api_key):
    """è·å–èŠå¤©å›å¤"""
    model = ChatOpenAI(
        base_url='https://api.openai-hk.com/v1/',
        openai_api_key=api_key,
        model='gpt-3.5-turbo'
    )
    chain = ConversationChain(llm=model, memory=memory)
    response = chain.invoke({'input': prompt})
    return response['response']

def qa_agent(api_key, memory, uploaded_file, question):
    """PDFé—®ç­”ä»£ç†"""
    model = ChatOpenAI(
        model='gpt-3.5-turbo',
        openai_api_key=api_key,
        base_url='https://api.openai-hk.com/v1/'
    )

    # è¯»å–ä¸Šä¼ çš„PDFå†…å®¹
    file_content = uploaded_file.read()

    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
    with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as temp_file:
        temp_file.write(file_content)
        temp_file_path = temp_file.name

    try:
        loader = PyPDFLoader(temp_file_path)
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=50,
            separators=['\n', 'ã€‚', 'ï¼Œ', '!', '?', ',', 'ã€', '']
        )

        texts = text_splitter.split_documents(docs)

        embedding_model = OpenAIEmbeddings(
            openai_api_key=api_key,
            base_url='https://api.openai-hk.com/v1/',
            model='text-embedding-3-large'
        )

        db = FAISS.from_documents(texts, embedding_model)
        retriever = db.as_retriever()

        qa = ConversationalRetrievalChain.from_llm(
            llm=model,
            retriever=retriever,
            memory=memory
        )

        response = qa.invoke({'question': question})
        return response
    
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_file_path):
            os.unlink(temp_file_path)

# é¡µé¢å‡½æ•°
def show_home():
    st.title("ğŸ‰ æ¬¢è¿ä½¿ç”¨AIå·¥å…·é›†åˆ")
    
    # å±…ä¸­æ˜¾ç¤ºåˆ¶ä½œå›¢é˜Ÿä¿¡æ¯
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.markdown("""
        <div style="text-align: center; padding: 50px; background-color: #f0f2f6; border-radius: 10px; margin: 50px 0;">
            <h2 style="color: #1f77b4;">åˆ¶ä½œå›¢é˜Ÿ</h2>
            <h3 style="color: #333;">å‚…å½¬å½¬ï¼Œè‘£æ”¿ï¼Œè‚ç¾¤æ¾ï¼Œä½•æ˜Ÿä¼½</h3>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # å·¥å…·ä»‹ç»
    st.markdown("## ğŸ› ï¸ å·¥å…·ä»‹ç»")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### ğŸ¬ ä¸€é”®ç”Ÿæˆè§†é¢‘è„šæœ¬
        - å¿«é€Ÿç”Ÿæˆå„ç±»è§†é¢‘è„šæœ¬
        - æ”¯æŒå¤šç§é£æ ¼å’Œç±»å‹
        - è‡ªåŠ¨ä¼˜åŒ–å†…å®¹ç»“æ„
        - åŸºäºLangChainå’ŒOpenAI GPT
        """)
        
        st.markdown("""
        ### ğŸ“ ç”Ÿæˆå°çº¢ä¹¦çˆ†æ¬¾æ–‡æ¡ˆ
        - æ™ºèƒ½ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆ
        - ä¼˜åŒ–æ ‡é¢˜å’Œå†…å®¹
        - æé«˜æ–‡æ¡ˆå¸å¼•åŠ›
        - åŒ…å«çˆ†æ¬¾å…³é”®è¯å’Œemoji
        """)
    
    with col2:
        st.markdown("""
        ### ğŸ’¬ å…‹éš†ChatGPT
        - æ™ºèƒ½å¯¹è¯ç³»ç»Ÿ
        - å¤šè½®å¯¹è¯èƒ½åŠ›
        - ä¸ªæ€§åŒ–å›å¤
        - æ”¯æŒä¸Šä¸‹æ–‡è®°å¿†
        """)
        
        st.markdown("""
        ### ğŸ“„ PDFæ–‡æ¡£é—®ç­”å·¥å…·
        - ä¸Šä¼ PDFæ–‡æ¡£
        - æ™ºèƒ½æ–‡æ¡£é—®ç­”
        - å¿«é€Ÿä¿¡æ¯æå–
        - åŸºäºå‘é‡æ£€ç´¢æŠ€æœ¯
        """)

def show_video_script():
    st.title("ğŸ¬ ä¸€é”®ç”Ÿæˆè§†é¢‘è„šæœ¬")
    
    if not openai_api_key:
        st.warning("âš ï¸ è¯·åœ¨å·¦ä¾§ä¾§æ è¾“å…¥OpenAI APIå¯†é’¥")
        return
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### ğŸ“ è„šæœ¬è®¾ç½®")
        
        subject = st.text_input('ğŸ’¡ è¯·è¾“å…¥è§†é¢‘çš„ä¸»é¢˜')
        video_length = st.number_input('è¯·è¾“å…¥è§†é¢‘çš„å¤§è‡´æ—¶é•¿(å•ä½: åˆ†é’Ÿ)', min_value=1, max_value=60, step=1, value=5)
        creativity = st.slider("â­ è¯·è¾“å…¥è§†é¢‘è„šæœ¬çš„åˆ›é€ åŠ›(æ•°å­—å°è¯´æ˜è¶Šä¸¥è°¨,æ•°å­—å¤§è¯´æ˜æ›´å¤šæ ·)", min_value=0.0, max_value=1.0, value=0.2, step=0.1)
        
        # ç”ŸæˆæŒ‰é’®
        if st.button("ğŸ¯ ç”Ÿæˆè§†é¢‘è„šæœ¬", type="primary", use_container_width=True):
            if not subject:
                st.warning("âš ï¸ è¯·è¾“å…¥è§†é¢‘ä¸»é¢˜")
                return
                
            with st.spinner('AIæ­£åœ¨æ€è€ƒä¸­,è¯·ç¨å...'):
                try:
                    title, script = generate_script(subject, video_length, creativity, openai_api_key)
                    
                    st.success('âœ… è§†é¢‘è„šæœ¬å·²ç”Ÿæˆ')
                    
                    st.subheader('ğŸ”¥ æ ‡é¢˜:')
                    st.write(title)

                    st.subheader('ğŸ“š è§†é¢‘è„šæœ¬: ')
                    st.write(script)
                    
                except Exception as e:
                    st.error(f"âŒ ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")
    
    with col2:
        st.markdown("### ğŸ’¡ ä½¿ç”¨æç¤º")
        st.info("""
        1. é€‰æ‹©åˆé€‚çš„è§†é¢‘ä¸»é¢˜
        2. è®¾å®šè§†é¢‘æ—¶é•¿
        3. è°ƒæ•´åˆ›é€ åŠ›å‚æ•°
        4. ç‚¹å‡»ç”ŸæˆæŒ‰é’®
        5. ç­‰å¾…AIç”Ÿæˆç»“æœ
        """)
        
        st.markdown("### ğŸ“Š è„šæœ¬ç‰¹ç‚¹")
        st.markdown("""
        - ğŸ¯ å¼€å¤´æŠ“ä½çœ¼çƒ
        - ğŸ“– ä¸­é—´æä¾›å¹²è´§
        - ğŸ‰ ç»“å°¾æœ‰æƒŠå–œ
        - ğŸ˜Š è½»æ¾æœ‰è¶£é£æ ¼
        """)

def show_xiaohongshu():
    st.title("ğŸ“ ç”Ÿæˆå°çº¢ä¹¦çˆ†æ¬¾æ–‡æ¡ˆ")
    
    if not openai_api_key:
        st.warning("âš ï¸ è¯·åœ¨å·¦ä¾§ä¾§æ è¾“å…¥OpenAI APIå¯†é’¥")
        return
    
    theme = st.text_input('ä¸»é¢˜')
    
    if st.button('âœ¨ å¼€å§‹å†™ä½œ', type="primary", use_container_width=True):
        if not theme:
            st.warning("âš ï¸ è¯·è¾“å…¥ä¸»é¢˜")
            return
            
        with st.spinner('AIæ­£åœ¨åŠªåŠ›åˆ›ä½œä¸­,è¯·ç¨å...'):
            try:
                result = generate_xiaohongshu(theme, openai_api_key)
                
                st.success("âœ… å°çº¢ä¹¦æ–‡æ¡ˆç”ŸæˆæˆåŠŸï¼")
                st.divider()

                left, right = st.columns(2)

                with left:
                    st.markdown('#### ğŸ”¥ çˆ†æ¬¾æ ‡é¢˜')
                    for i, title in enumerate(result.titles[:5], 1):
                        st.markdown(f'**æ ‡é¢˜{i}ï¼š** {title}')

                with right:
                    st.markdown('#### ğŸ“ å°çº¢ä¹¦æ­£æ–‡')
                    st.write(result.content)
                    
            except Exception as e:
                st.error(f"âŒ ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")

def show_chatgpt_clone():
    st.title("ğŸ’¬ å…‹éš†ChatGPT")
    
    if not openai_api_key:
        st.warning("âš ï¸ è¯·åœ¨å·¦ä¾§ä¾§æ è¾“å…¥OpenAI APIå¯†é’¥")
        return
    
    # ç®¡ç†ä¼šè¯çŠ¶æ€
    if 'memory' not in st.session_state:
        st.session_state['memory'] = ConversationBufferMemory(return_messages=True)
        st.session_state['messages'] = [{'role': 'ai', 'content': 'ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼Ÿ'}]

    # èŠå¤©è®¾ç½®
    with st.sidebar:
        st.markdown("### âš™ï¸ èŠå¤©è®¾ç½®")
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯"):
            st.session_state['memory'] = ConversationBufferMemory(return_messages=True)
            st.session_state['messages'] = [{'role': 'ai', 'content': 'ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼Ÿ'}]
            st.rerun()

    # æ˜¾ç¤ºèŠå¤©å†å²
    for message in st.session_state['messages']:
        st.chat_message(message['role']).write(message['content'])

    # è·å–ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯å†å²
        st.session_state['messages'].append({'role': 'human', 'content': prompt})
        st.chat_message('human').write(prompt)

        with st.spinner('AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰.....'):
            try:
                response = get_chat_response(prompt, st.session_state['memory'], openai_api_key)
                
                # å¤„ç†AIå“åº”å¹¶æ·»åŠ åˆ°å¯¹è¯å†å²
                msg = {'role': 'ai', 'content': response}
                st.session_state['messages'].append(msg)
                st.chat_message('ai').write(response)
                
            except Exception as e:
                st.error(f"âŒ å›å¤å¤±è´¥ï¼š{str(e)}")

def show_pdf_qa():
    st.title("ğŸ“„ PDFæ–‡æ¡£é—®ç­”å·¥å…·")
    
    if not openai_api_key:
        st.warning("âš ï¸ è¯·åœ¨å·¦ä¾§ä¾§æ è¾“å…¥OpenAI APIå¯†é’¥")
        return
    
    # åˆå§‹åŒ–PDFé—®ç­”çš„å†…å­˜
    if "pdf_memory" not in st.session_state:
        st.session_state["pdf_memory"] = ConversationBufferMemory(
            return_messages=True,
            memory_key="chat_history",
            output_key="answer"
        )

    uploaded_file = st.file_uploader("ğŸ“ ä¸Šä¼ ä½ çš„PDFæ–‡ä»¶ï¼š", type="pdf")
    question = st.text_input("ğŸ’­ å¯¹PDFçš„å†…å®¹è¿›è¡Œæé—®", disabled=not uploaded_file)

    if uploaded_file and question:
        with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰..."):
            try:
                response = qa_agent(openai_api_key, st.session_state["pdf_memory"], uploaded_file, question)
                
                st.success("âœ… é—®ç­”å®Œæˆ")
                st.markdown("### ğŸ’¡ ç­”æ¡ˆ")
                st.write(response["answer"])
                
                # ä¿å­˜èŠå¤©å†å²åˆ°session state
                st.session_state["chat_history"] = response["chat_history"]
                
            except Exception as e:
                st.error(f"âŒ é—®ç­”å¤±è´¥ï¼š{str(e)}")

    # æ˜¾ç¤ºå†å²æ¶ˆæ¯
    if "chat_history" in st.session_state:
        with st.expander("ğŸ“ å†å²æ¶ˆæ¯"):
            for i in range(0, len(st.session_state["chat_history"]), 2):
                if i + 1 < len(st.session_state["chat_history"]):
                    human_message = st.session_state["chat_history"][i]
                    ai_message = st.session_state["chat_history"][i + 1]
                    
                    st.markdown(f"**ğŸ™‹ é—®é¢˜ï¼š** {human_message.content}")
                    st.markdown(f"**ğŸ¤– å›ç­”ï¼š** {ai_message.content}")
                    
                    if i < len(st.session_state["chat_history"]) - 2:
                        st.divider()

# æ ¹æ®é€‰æ‹©çš„é¡µé¢æ˜¾ç¤ºç›¸åº”å†…å®¹
if st.session_state.selected_page == "é¦–é¡µ":
    show_home()
elif st.session_state.selected_page == "è§†é¢‘è„šæœ¬":
    show_video_script()
elif st.session_state.selected_page == "å°çº¢ä¹¦æ–‡æ¡ˆ":
    show_xiaohongshu()
elif st.session_state.selected_page == "ChatGPTå…‹éš†":
    show_chatgpt_clone()
elif st.session_state.selected_page == "PDFé—®ç­”":
    show_pdf_qa()

# é¡µè„š
st.markdown("---")
st.markdown(
    """
    <div style="text-align: center; color: #666; padding: 20px;">
        Â© 2025 AIå·¥å…·é›†åˆ | åˆ¶ä½œå›¢é˜Ÿï¼šå‚…å½¬å½¬ï¼Œè‘£æ”¿ï¼Œè‚ç¾¤æ¾ï¼Œä½•æ˜Ÿä¼½
    </div>
    """, 
    unsafe_allow_html=True
)
